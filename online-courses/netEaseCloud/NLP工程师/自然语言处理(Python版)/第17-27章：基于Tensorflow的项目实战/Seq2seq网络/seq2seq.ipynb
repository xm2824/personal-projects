{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seq2seq with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq2seq网络架构:\n",
    "![seq2seq 网络架构](pictures/1-seq2seq.png)\n",
    "Encoder 获得输入 `[A, B, C]` . 我们不关心encoder的输出是什么, 只需要得到它最后的隐含状态就可以了，将它传递给decoder端, 输入为 `[<EOS>, W, X, Y, Z]` 训练的目标为 `[W, X, Y, Z, <EOS>]`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary\n",
    "\n",
    "如果是文本数据，则需要首先建立词库表，就是把词和对应的ID做好映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [[5, 7, 8], [6, 3], [3], [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers\n",
    "xt, xlen = helpers.batch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 7, 8], [6, 3], [3], [1]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 6, 3, 1],\n",
       "       [7, 3, 0, 0],\n",
       "       [8, 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 1, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helpers\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 20\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = encoder_hidden_units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `encoder_inputs` int32 tensor is shaped `[encoder_max_time, batch_size]`\n",
    "- `decoder_targets` int32 tensor is shaped `[decoder_max_time, batch_size]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `decoder_inputs` int32 tensor is shaped `[decoder_max_time, batch_size]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n",
    "\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell, encoder_inputs_embedded,\n",
    "    dtype=tf.float32, time_major=True,\n",
    ")\n",
    "\n",
    "del encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 20) dtype=float32>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)\n",
    "\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    decoder_cell, decoder_inputs_embedded,\n",
    "\n",
    "    initial_state=encoder_final_state,\n",
    "\n",
    "    dtype=tf.float32, time_major=True, scope=\"plain_decoder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_logits = tf.contrib.layers.linear(decoder_outputs, vocab_size)\n",
    "\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'fully_connected/BiasAdd:0' shape=(?, ?, 10) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of the batch:\n",
      "[5, 5, 7, 8, 8]\n",
      "[7, 3, 3]\n",
      "[3, 3, 2, 3]\n",
      "[3, 4, 7, 5, 9, 2]\n",
      "[4, 9, 7, 8, 6, 5, 6]\n",
      "[7, 6, 2]\n",
      "[2, 9, 2, 7, 9, 5]\n",
      "[5, 7, 2, 8, 6, 2, 9]\n",
      "[9, 4, 9, 4, 4, 7]\n",
      "[5, 2, 7]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "batches = helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "print('head of the batch:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    encoder_inputs_, _ = helpers.batch(batch)\n",
    "    decoder_targets_, _ = helpers.batch(\n",
    "        [(sequence) + [EOS] for sequence in batch]\n",
    "    )\n",
    "    decoder_inputs_, _ = helpers.batch(\n",
    "        [[EOS] + (sequence) for sequence in batch]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        decoder_inputs: decoder_inputs_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入 `[5, 6, 7]`, decoder_targets `[5, 6, 7, 1]`,  其中 1 代表 `EOS`, decoder_inputs `[1, 5, 6, 7]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.3390607833862305\n",
      "  sample 1:\n",
      "    input     > [3 6 9 5 6 4 2 6]\n",
      "    predicted > [6 5 8 9 9 8 9 9 8]\n",
      "  sample 2:\n",
      "    input     > [4 2 6 6 5 0 0 0]\n",
      "    predicted > [6 7 7 7 7 8 9 9 9]\n",
      "  sample 3:\n",
      "    input     > [3 8 9 6 9 4 8 5]\n",
      "    predicted > [6 3 3 9 3 9 3 3 9]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.30939382314682007\n",
      "  sample 1:\n",
      "    input     > [9 5 9 9 7 2 0 0]\n",
      "    predicted > [9 9 9 9 7 2 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 3 7 7 4 9 0 0]\n",
      "    predicted > [9 3 7 7 4 9 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 7 2 4 2 7 5 0]\n",
      "    predicted > [7 7 2 4 2 7 5 1 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.15077874064445496\n",
      "  sample 1:\n",
      "    input     > [5 7 2 4 3 8 0 0]\n",
      "    predicted > [5 7 2 4 3 8 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 8 4 6 3 6 7 7]\n",
      "    predicted > [4 8 4 6 7 7 7 7 1]\n",
      "  sample 3:\n",
      "    input     > [4 9 4 0 0 0 0 0]\n",
      "    predicted > [4 9 4 1 0 0 0 0 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.09187103807926178\n",
      "  sample 1:\n",
      "    input     > [3 9 3 0 0 0 0 0]\n",
      "    predicted > [3 9 3 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 5 2 3 2 0 0 0]\n",
      "    predicted > [9 5 2 3 2 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 8 7 0 0 0 0 0]\n",
      "    predicted > [7 8 7 1 0 0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_batches = 3001\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "try:\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "\n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.1038 after 300100 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22408039400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
